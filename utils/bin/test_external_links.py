#!/usr/bin/env python3
"""
Test script for external link checking functionality
"""

import requests
from bs4 import BeautifulSoup
import time
import re


def test_external_link_extraction():
 """Test extracting external links from a page."""
 print("ğŸ§ª Testing external link extraction...")

 # Test with a simple page
 test_url = "https://unixwzrd.ai/"

 try:
 response = requests.get(test_url, timeout=10)
 response.raise_for_status()

 soup = BeautifulSoup(response.content, "html.parser")
 external_links = []

 # Find all links
 for link in soup.find_all("a", href=True):
 href = link["href"]

 # Skip internal links, anchors, javascript, mailto, etc.
 if (
 href.startswith("#")
 or href.startswith("javascript:")
 or href.startswith("mailto:")
 or href.startswith("tel:")
 or href.startswith("/")
 or href.startswith("https://unixwzrd.ai")
 or not href.startswith(("http://", "https://"))
 ):
 continue

 external_links.append(href)

 # Also check for external links in content
 content = response.text
 url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
 urls = re.findall(url_pattern, content)

 for url in urls:
 if not url.startswith("https://unixwzrd.ai"):
 external_links.append(url)

 external_links = list(set(external_links)) # Remove duplicates

 print(f"âœ… Found {len(external_links)} external links:")
 for link in external_links[:5]: # Show first 5
 print(f" - {link}")
 if len(external_links) > 5:
 print(f" ... and {len(external_links) - 5} more")

 return external_links

 except Exception as e:
 print(f"âŒ Error extracting links: {e}")
 return []


def test_external_link_checking():
 """Test checking external links."""
 print("\nğŸ§ª Testing external link checking...")

 # Test with some known good and bad links
 test_links = [
 "https://www.google.com",
 "https://httpbin.org/status/404",
 "https://httpbin.org/status/500",
 "https://httpbin.org/delay/2", # Slow link
 "https://nonexistent-domain-12345.com", # Bad link
 ]

 for link in test_links:
 try:
 start_time = time.time()
 response = requests.head(link, timeout=10, allow_redirects=True)
 response_time = time.time() - start_time

 if response.status_code < 400:
 status = "working"
 if response_time > 5.0:
 status = "slow"
 print(f"âœ… {link}: {status} ({response_time:.2f}s)")
 else:
 print(f"âŒ {link}: broken ({response.status_code})")

 except requests.exceptions.Timeout:
 print(f"âŒ {link}: timeout")
 except requests.exceptions.ConnectionError:
 print(f"âŒ {link}: connection error")
 except Exception as e:
 print(f"âŒ {link}: error - {e}")


if __name__ == "__main__":
 print("ğŸ”— External Link Testing")
 print("=" * 40)

 # Test link extraction
 links = test_external_link_extraction()

 # Test link checking
 test_external_link_checking()

 print("\nâœ… External link testing completed!")

